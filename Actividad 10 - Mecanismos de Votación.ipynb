{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 10 - Mecanismos de Votación\n",
    "### Desafío 1 - Preparación del Ambiente de Trabajo\n",
    "- Describa el comportamiento de las variables.\n",
    "- Dada la naturaleza de los atributos, es probable que algunas mediciones estén correlacionadas entre sí. Para ello, genere un diagnóstico previo de multicolinealidad utilizando la función identify_high_correlations que se encuentra en el archivo helpers.py . Para todos aquellos atributos que tengan una correlación de .8, reporte sus nombres.\n",
    "- Antes de generar los conjuntos de entrenamiento y validación, preprocese los datos con los siguientes pasos:\n",
    "- Recodifique la variable shares en una variable binaria que identifique como 1 todos los registros con más de 1400 \"compartir\" y 0 de lo contrario. Para evitar multicolinealidad, elimine la variable shares posteriormente.\n",
    "- Elimine todas las variables que presentaban una correlación mayor a .8. Este paso es para evitar la multicolinealidad de los atributos.\n",
    "- Genere un análisis de Componentes Principales para extraer las principales 30 dimensiones. Guarde estas dimensiones en un nuevo objeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import helpers\n",
    "import re\n",
    "seed = 602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./OnlineNewsPopularity/OnlineNewsPopularity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las etiquetas de las columnas presentan un espacio extra, con ésto lo podemos eliminar\n",
    "df.columns = [i.replace(' ', '') for i in df.columns]\n",
    "# eliminamos el string de url que no sirve para el análisis\n",
    "df = df.loc[:, 'n_tokens_title':'shares']\n",
    "# generamos el conjunto de variables\n",
    "qnty = df.filter(regex='^n_', axis=1)\n",
    "channel = df.filter(regex='^data_', axis=1)\n",
    "days = df.filter(regex=re.compile(\"weekday|weekend\"), axis=1)\n",
    "sentiments = df.filter(regex=re.compile(\"negative|positive|subjectivity\"), axis=1) \n",
    "lda = df.filter(regex='^LDA_\\d', axis=1)\n",
    "keywords = df.filter(regex='^kw_', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,25))\n",
    "cols = 5\n",
    "rows = np.ceil(df.shape[1] / cols)\n",
    "\n",
    "for i, (colname, serie) in enumerate(df.iteritems()):\n",
    "    plt.subplot(rows,cols,i+1)\n",
    "    if (len(serie.value_counts()) > 2):\n",
    "        sns.distplot(serie)\n",
    "    else:\n",
    "        sns.countplot(serie)\n",
    "        \n",
    "plt.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Tenemos un número de atributos binarios, especialmente respecto al día y la categoría del artículo\n",
    " - Algunas variables tienen comportamiento relativamente normal como `global_subjectivity`, `global_sentiment_polarity`, `global_rate_positive_words`, `avg_positive_polarity`.\n",
    " - Luego otro grupo de atributos son evaluaiones de 0 a 1/-1, que corresponden a tasas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostramos los valores de correlaciones mayores a 0.8. Aprovechamos de arreglar el helpers ajajaj\n",
    "\n",
    "corr = helpers.identify_high_correlations(df,threshold = 0.8)\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=corr['var2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shares'] = np.where(df['shares'] > 1400, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shares'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30)\n",
    "pca_dim = pca.fit_transform(df.drop(columns=['shares']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafío 2 - Evaluación de modelos individuales\n",
    "- A continuación generará una serie de modelos que se incorporarán posteriormente al comité de votación. Para ello, se solicita que:\n",
    "  - Importe los módulos correctamente.\n",
    "  - Para cada uno de ellos, genere un reporte en las métricas de desempeño respecto a\n",
    "  - Precision , Recall , F1 . Puede hacer uso de la función plot_classification_report disponible en el archivo helpers.py .\n",
    "  - Comente el desempeño general de cada uno\n",
    "\n",
    "- La lista de modelos es la siguiente. Cabe destacar que la mayoría de éstos corresponden a implementaciones vanilla, salvo que se indique lo contrario:\n",
    "  - Regresión Logística.\n",
    "  - Algoritmo de KMedias.\n",
    "  - Árbol de Clasificación con un max_depth=1 .\n",
    "  - Árbol de Clasificación con un max_depth=4 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pca_dim, df['shares'], test_size=.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=seed)),\n",
    "    ('Muñon Tree', DecisionTreeClassifier(max_depth=1, random_state=seed)),\n",
    "    ('Four Tree', DecisionTreeClassifier(max_depth=4, random_state=seed)),\n",
    "    ('Kmeans', KMeans(n_clusters=2, random_state=seed))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "cr =  dict()\n",
    "for index, i in enumerate(ensamble):\n",
    "    yhat = i[1].fit(X_train, y_train).predict(X_test)\n",
    "    plt.subplot(2,2,index+1)\n",
    "    plt.title(i[0])\n",
    "    helpers.plot_classification_report(y_test, yhat)\n",
    "    if (index  == 1):\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.xlim((0, 1.0))\n",
    "    cr.update({i[0]: pd.DataFrame(classification_report(y_test, yhat, output_dict=True))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El Modelo Kmeans presenta los peores resultados para identificar la Clase 1, pero los mejores para la clase 0\n",
    "- El árbol de profundidad 4 y la regresión logística presentan los mejores resultados. El primero presenta resultados mejores para la clase 1 y el segundo para la clase 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafío 3- Entrenamiento de Comité\n",
    "- Entrene el comité de clasificadores sin modificar el esquema de votación.\n",
    "- Reporte el desempeño a nivel de cada clase para cada métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier = VotingClassifier(ensamble).fit(X_train, y_train)\n",
    "yhat_vc = voting_classifier.predict(X_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Clasificación por Votación')\n",
    "helpers.plot_classification_report(y_test, yhat_vc)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlim((0, 1.0));\n",
    "\n",
    "cr.update({'Voting': pd.DataFrame(classification_report(y_test, yhat_vc, output_dict=True))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd.DataFrame()\n",
    "for i in cr:\n",
    "    aux[i]=cr[i]['0']\n",
    "aux\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd.DataFrame()\n",
    "for i in cr:\n",
    "    aux[i]=cr[i]['1']\n",
    "aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para la Clase 0, el mejor modelo es el de Voting considerando la métrica f1. Sin embargo la mejor presicion correponde al árbol de decisión de 4 de profundidad. KMeans de los que predijo como positivos, un buen porcentaje (92%) fue correcto\n",
    "- Para la Clase 1, el mejor modelo es Four Tree. Respecto la presición de los datos correctos, el Voting tuvo mejor resultado. En este caso KMeans tiene un muy mal porcentaje de recall.\n",
    "- Podemos decir que KMeans sobreestima las clases 0, lo que explica su alto recall para esa clase. Efecto similar ocurre con el muñon de decisión. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafío 4 - Calibración de Comité con Ponderadores\n",
    "- El base al comportamiento de los clasificadores individuales del ensamble, proponga dos esquemas de ponderación para mejorar el desempeño del modelo.\n",
    "- Reporte el desempeño del mejor ensamble heterogéneo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_hyperparams = {\n",
    "'AumentoLR/FT': [.375, .125, .375, .125],\n",
    "'SoloLR/FT': [.5, .0, .5, .0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier2 = VotingClassifier(ensamble, weights=weights_hyperparams['AumentoLR/FT']).fit(X_train, y_train)\n",
    "yhat_vc = voting_classifier2.predict(X_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Clasificación por Votación AumentoLR/FT')\n",
    "helpers.plot_classification_report(y_test, yhat_vc)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlim((0, 1.0));\n",
    "\n",
    "cr.update({'Voting AumentoLR/FT': pd.DataFrame(classification_report(y_test, yhat_vc, output_dict=True))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier3 = VotingClassifier(ensamble, weights=weights_hyperparams['SoloLR/FT']).fit(X_train, y_train)\n",
    "yhat_vc = voting_classifier3.predict(X_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Clasificación por Votación SoloLR/FT')\n",
    "helpers.plot_classification_report(y_test, yhat_vc)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlim((0, 1.0));\n",
    "\n",
    "cr.update({'Voting SoloLR/FT': pd.DataFrame(classification_report(y_test, yhat_vc, output_dict=True))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd.DataFrame()\n",
    "for i in cr:\n",
    "    aux[i]=cr[i]['0']\n",
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd.DataFrame()\n",
    "for i in cr:\n",
    "    aux[i]=cr[i]['1']\n",
    "aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El mejor ensamble es el que solo considera la Regresión Logística y el Árbol de Decisión de 4 de profundidad para aquellas publicaciones con menos _shares_\n",
    "- El mismo árbol es el mejor modelo para predecir publicaciones populares, pero de los ensambles el que pondera de menor manera los modelos KMeans y muñón de decisión son los mejores. \n",
    "- Sin embargo considerando precision el modelo SoloLR/FT es aquel que logra predecir aquellos publicaciones que verdaderamente son populares, pero entrega muchos falsos negativos. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
